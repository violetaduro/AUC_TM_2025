{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQzYGMVl4-1n"
   },
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dloey_mk4-1q"
   },
   "source": [
    "## Guidelines\n",
    "\n",
    "> Remember that this is a code notebook - add an explanation of what you do using text boxes and markdown, and comment your code. Answers without explanations may get less points.\n",
    ">\n",
    "> If you re-use a substantial portion of code you find online, e.g on Stackoverflow, you need to add a link to it and make the borrowing explicit. The same applies of you take it and modify it, even substantially. There is nothing bad in doing that, providing you are acknowledging it and make it clear you know what you're doing.\n",
    ">\n",
    "> The **Generative AI policy** from the syllabus for the programming assignments applies. Generative AI can be used as a source of information in these assignments if properly referenced. You can use generative AI assistance for writing code, but you must reference the chat used as a source, just as if you would take from StackOverflow. In ChatGPT, you can make an URL to the information you obtained by clicking the \"Share link to Chat\" button and then \"Copy Link\". This allows you to cite the source of the information you use in your answer or code solution. Of course, as you know, GenAI tools are not always a reliable source and its answers are intransparantly drawn from other sources - it is recommended to cross-check its output with other sources or your own understanding of the topic.\n",
    "> \n",
    "> For the explanations of what you do that you provide with each question, as well as for (sub)questions that ask about things like motivation of choices or your opinion, the answer to this must be conceptualized and written by yourself and not copied from a generative AI source.\n",
    ">\n",
    "> Make sure your notebooks have been run when you submit, as I won't run them myself. Submit both the `.ipynb` file along with an `.html` export of the same. Submit all necessary auxilliary files as well. Please compress your submission into a `.zip` archive. Only `.zip` files can be submitted.\n",
    "> If you are using Google Colab, here is a tutorial for obtaining an HTML export: https://stackoverflow.com/questions/53460051/convert-ipynb-notebook-to-html-in-google-colab .\n",
    ">\n",
    "> With Jupyter, you can simply export it as HTML through the File menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfy-TozC4-1s"
   },
   "source": [
    "## Grading policy\n",
    "> As follows:\n",
    ">\n",
    "> * 80 points for correctly completing the assignment.\n",
    ">\n",
    "> * 20 points for appropriately writing and organizing your code in terms of structure, readibility (also by humans), comments and minimal documentation. It is important to be concise but also to explain what you did and why, when not obvious. Feel free to re-use functions and variables from previous questions if that helps for structure and readability - you do not need to repeat previous steps for each question.\n",
    "> \n",
    "> Note that there are no extras for this assignment, as all 100 points are accrued via questions and question 6 has 10 'advanced' points to get.\n",
    "\n",
    "**The AUC code of conduct applies to this assignment: please only submit your own work and follow the instructions on referencing external sources above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRnI9EF74-1t"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmAFtiS14-1u"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this assignment, you will build and compare classifiers for measuring the **sentiment of tweets related to COVID-19** from the early days of the first outbreak.\n",
    "\n",
    "The dataset you will work with is [publicly available in Kaggle](https://www.kaggle.com/datatattle/covid-19-nlp-text-classification) (and attached to the assignment for your convenience). Make sure to check its minimal Kaggle documentation before starting.\n",
    "\n",
    "This is a real dataset, and therefore messy. It is possible that you won't achieve great results on the classification task with your classifier. That is normal, don't worry about it! You also may find text encoding issues with this dataset. Try to find a simple solution to this problem, I don't think there is an easy way to fix it completely for these files.\n",
    "\n",
    "*Please note: this dataset should not but might contain content which could be considered as offensive.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rv4avAae4-1v"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTwyDa3M4-1v"
   },
   "source": [
    "# Skeleton pipeline (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXgFtpSY4-1x"
   },
   "source": [
    "## Question 1 (8 points)\n",
    "\n",
    "Your dataset contains tweets, including handlers, hashtags, URLs, etc. Set-up a **minimal pre-processing pipeline** for them (focus on the `OriginalTweet` column), possibly including:\n",
    "\n",
    "* Tokenization\n",
    "* Filtering\n",
    "* Lemmatization/Stemming\n",
    "\n",
    "Please note that what to include is up to you, motivate your choices and remember that more is not necessarily better: if you are not sure why you are doing something, it might be better not to. Feel free to use NLTK, spaCy or anything else you like here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WZ2OPwtS4-10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Try with an explicit encoding because it didn't work with the default because of the special characters in the CSV file.\n",
    "df_train = pd.read_csv(\"data/Corona_NLP_train.csv\", encoding='latin-1')\n",
    "\n",
    "# check the first few rows of the dataframe\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcGyC86g4-13"
   },
   "source": [
    "*Note: we only really use the `OriginalTweet` and `Sentiment` columns for this assignment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AbGfZgBN4-14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\viole\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\viole\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>ProcessedTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>advice talk neighbour family exchange phone nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>coronavirus australia : woolworth give elderly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>food stock one empty ... please , panic , enou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>, ready go supermarket #covid19 outbreak . par...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n",
       "1  advice Talk to your neighbours family to excha...   \n",
       "2  Coronavirus Australia: Woolworths to give elde...   \n",
       "3  My food stock is not the only one which is emp...   \n",
       "4  Me, ready to go at supermarket during the #COV...   \n",
       "\n",
       "                                      ProcessedTweet  \n",
       "0                                                     \n",
       "1  advice talk neighbour family exchange phone nu...  \n",
       "2  coronavirus australia : woolworth give elderly...  \n",
       "3  food stock one empty ... please , panic , enou...  \n",
       "4  , ready go supermarket #covid19 outbreak . par...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#preprocessing function\n",
    "def preprocess_tweets(tweet_series):\n",
    "    # Initialize the tokenizer, stop words, and lemmatizer\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    processed_tweets = []\n",
    "    \n",
    "    # fucntion to itinerate through each tweet in the series\n",
    "    for tweet in tweet_series:\n",
    "        # for removing URLs with regex\n",
    "        tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', str(tweet), flags=re.MULTILINE)\n",
    "        \n",
    "        # to handle COVID-specific terms consistently\n",
    "        tweet = tweet.replace(\"covid-19\", \"covid19\").replace(\"coronavirus\", \"covid19\")\n",
    "        \n",
    "        # tokenizing the tweet\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        \n",
    "        # removing stopwords and lemmatizing\n",
    "        cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens \n",
    "                         if token not in stop_words and not token.startswith('@')]\n",
    "        \n",
    "        # finally join tokens back into a string\n",
    "        processed_tweets.append(' '.join(cleaned_tokens))\n",
    "    \n",
    "    return processed_tweets\n",
    "\n",
    "# to ap´ply preprocessing to the OriginalTweet column\n",
    "df_train['ProcessedTweet'] = preprocess_tweets(df_train['OriginalTweet'])\n",
    "\n",
    "# and display some examples of original vs processed tweets\n",
    "df_train[['OriginalTweet', 'ProcessedTweet']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to remove Twitter handles because it's not information that we need right now. Also urls, because didn't add anything to the analysis. This two things are used to reduce noise from the data. I also normalized the text with lowercase, stopwords and lemmatization to keep important context words. And I thought preserving the hashtags is important because they usually give important information for the context and they use to resume good the information of the tweet. I finally thought that adding a normalization step in my preprocessing function that would help with the specific terms for COVID, since there are a lot and they mean the same. (coronavirus, covid19...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeR26J-N4-15"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyDE26-i4-15"
   },
   "source": [
    "## Question 2 (4 points)\n",
    "\n",
    "**Split your data into a train and a validation set**. You can use 85% for training and 15% for validation, or similar proportions. Remember to shuffle your data before splitting, specifying a seed to be able to replicate your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9vWDVkRB4-16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 41157\n",
      "Training set size: 34983 (85.0%)\n",
      "Validation set size: 6174 (15.0%)\n",
      "\n",
      "Sample from training set:\n",
      "                                       OriginalTweet  \\\n",
      "0  #Coronavirus spreads by touching a surface or ...   \n",
      "1  @SiouxsieW and any other experts. Question in ...   \n",
      "\n",
      "                                      ProcessedTweet  \n",
      "0  #coronavirus spread touching surface object vi...  \n",
      "1  expert . question house breakfast morning : cl...  \n",
      "\n",
      "Sample from validation set:\n",
      "                                       OriginalTweet  \\\n",
      "0   Without the there would not be any problem wh...   \n",
      "1  Rice &amp; wheat prices surge amid fears Covid...   \n",
      "\n",
      "                                      ProcessedTweet  \n",
      "0  without would problem whatsoever people gettin...  \n",
      "1  rice & wheat price surge amid fear covid - 19 ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# shuffling and spliting the data into training (85%) and validation (15%) sets\n",
    "train_df, val_df = train_test_split(\n",
    "    df_train,\n",
    "    test_size=0.15,  # 15% for validation\n",
    "    random_state=RANDOM_SEED,  # seed for reproducibility\n",
    "    shuffle=True  # to make sure we are shuffling the data before splitting\n",
    ")\n",
    "\n",
    "# check the size of the original dataset and the split datasets\n",
    "print(f\"Original dataset size: {len(df_train)}\")\n",
    "print(f\"Training set size: {len(train_df)} ({len(train_df)/len(df_train)*100:.1f}%)\")\n",
    "print(f\"Validation set size: {len(val_df)} ({len(val_df)/len(df_train)*100:.1f}%)\")\n",
    "\n",
    "# rest the index of the dataframes to start from 0 after the split\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "# I need to check a few samples from each set to verify the split worked properly\n",
    "print(\"\\nSample from training set:\")\n",
    "print(train_df[['OriginalTweet', 'ProcessedTweet']].head(2))\n",
    "\n",
    "print(\"\\nSample from validation set:\")\n",
    "print(val_df[['OriginalTweet', 'ProcessedTweet']].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpfNtdX04-16"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I328Auig4-17"
   },
   "source": [
    "## Question 3 (8 points)\n",
    "\n",
    "Write a function which, given as input a set of predictions and a set of ground truth labels and the name of the method, prints out a **classification report** including:\n",
    "* Name of the method\n",
    "* Accuracy\n",
    "* Precision, recall and F1 measure\n",
    "* An example of a correctly classified datapoint (e.g. a tweet)\n",
    "* An example of a wrongly classified datapoint\n",
    "\n",
    "*Note: You can do this question at the same time as question 4 so that you have something to report (the result of the baseline)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZG3nFTa4-18"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, texts, method_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    y_true: list or array of ground truth labels\n",
    "    y_pred: list or array of predicted labels\n",
    "    texts: the corresponding list of texts (e.g., tweets)\n",
    "    method_name: name of the method (e.g., 'Baseline', 'LogReg', etc.)\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Evaluation Report: {method_name} ===\")\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Precision, Recall, F1\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"Precision (weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (weighted):    {recall:.4f}\")\n",
    "    print(f\"F1-score (weighted):  {f1:.4f}\")\n",
    "    \n",
    "    # Full classification report\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "    # Correctly classified example\n",
    "    for true_label, pred_label, text in zip(y_true, y_pred, texts):\n",
    "        if true_label == pred_label:\n",
    "            print(\"\\nExample of correctly classified tweet:\")\n",
    "            print(f\"Tweet: {text}\")\n",
    "            print(f\"Label: {true_label}\")\n",
    "            break\n",
    "\n",
    "    # Incorrectly classified example\n",
    "    for true_label, pred_label, text in zip(y_true, y_pred, texts):\n",
    "        if true_label != pred_label:\n",
    "            print(\"\\nExample of wrongly classified tweet:\")\n",
    "            print(f\"Tweet: {text}\")\n",
    "            print(f\"True label: {true_label}, Predicted: {pred_label}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwLrjSBV4-18"
   },
   "source": [
    "# Classifying (45 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will be performing classification on real data, processes may take a while to run. This is normal, but it should not take hours. Here's some advice if you find that some of your code takes a long time to run:\n",
    "- If you are doing a hyperparameter search, try to make it quite small. Every hyperparameter combination that you try means training a new model, and runtimes can explode. You do not need to do a huge search for this assignment, it is enough if I can see that you are able to do it with a small example.\n",
    "- If you are doing a grid search, try to know how many combinations of hyperparameters your code will check and try to have print statements to know where you are at. Computation time grows exponentially for each additional hyperparameter option so this can get out of hand quickly. Also, if training a single model as a step of your grid search takes longer than just training the model separately, there might be an issue with your grid search code.\n",
    "- In a real project, you would want to make your code such that you can pause and resume training or optimization without having to re-do everything, e.g. by writing the results to a file. But for the purpose of this assignment it is not necessary to make it that complicated.\n",
    "- Use separate code blocks especially for the part of code that trains a model. That way, you only need to run the training step once, while you can mess around with the output/evaluation etc. without having to wait for a new model to be trained each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_gI9lIS4-19"
   },
   "source": [
    "## Question 4 (10 points)\n",
    "\n",
    "An important first step when dealing with a real-world task is establishing a **solid baseline**. The baseline allows to a) develop the first full pipeline for your task, and b) to have something to compare against when you develop more advanced models.\n",
    "\n",
    "Pick a method to use as a baseline. *A good option might be a TF-IDF Logistic Regression*. Feel free to use scikit-learn or another library of choice. See [here](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) for more options.\n",
    "\n",
    "Use your classification report function and the validation set to report on the performance of your baseline. *Pay attention: the validation data only needs to be transformed, and must not be used to fit any transformation. For example, if you have used a TF-IDF vectorizer by fitting it to your train data and then transformed it, use the same fitted vectorizer to transform your validation data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#  x is used to store the preprocessed tweets and y is used to store the sentiment labels\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# for training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m X_train = \u001b[43mtrain_df\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mProcessedTweet\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      8\u001b[39m y_train = train_df[\u001b[33m'\u001b[39m\u001b[33mSentiment\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# for validation\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#  x is used to store the preprocessed tweets and y is used to store the sentiment labels\n",
    "# for training\n",
    "X_train = train_df['ProcessedTweet']\n",
    "y_train = train_df['Sentiment']\n",
    "# for validation\n",
    "X_val = val_df['ProcessedTweet']\n",
    "y_val = val_df['Sentiment']\n",
    "\n",
    "# 1. transform the tweets into TF-IDF features and the 5000 most frequent words\n",
    "tfidf = TfidfVectorizer(max_features=5000) \n",
    "\n",
    "# 2. adjust the vectorizer to the training set, only to the training set\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# 3. here I use the already fitted vectorizer to transform the validation set\n",
    "X_val_tfidf = tfidf.transform(X_val)\n",
    "\n",
    "# 4. train the logistic regression model\n",
    "# I use the default parameters of LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 5. predict the sentiment labels for the validation set\n",
    "y_pred = model.predict(X_val_tfidf)\n",
    "\n",
    "# 6. we use the evaluation function to evaluate the model of exercise 3, so here we can see the results of the model also\n",
    "evaluate_predictions(y_val, y_pred, val_df['OriginalTweet'], method_name=\"TF-IDF + Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnnmO3Kf4-1-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOE_ZHLv4-1-"
   },
   "source": [
    "## Question 5 (20 points)\n",
    "\n",
    "Try now to **beat your baseline**. Feel free to use scikit-learn or another library of choice. See [here](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) for more options.\n",
    "\n",
    "How to beat the baseline? There are many ways:\n",
    "1. You could have a better text representation (e.g., using PPMI instead of TF-IDF, note that this is challenging because there is no ready-made scikit-learn vectorizer for this).\n",
    "2. You can pick a more powerful model (e.g., random forests or SVMs).\n",
    "3. You have to find good hyperparameters for your model, and not just use the default ones.\n",
    "\n",
    "Regarding point 3 above, make sure to perform some hyperparameter searching using [grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) or [randomized search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "Use your classification report function and the validation set to report on the performance of your baseline. *Pay attention: the validation data only needs to be transformed, and must not be used to fit any transformation. For example, if you have used a TF-IDF vectorizer by fitting it to your train data and then transformed it, use the same fitted vectorizer to transform your validation data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "=== Evaluation Report: Tuned TF-IDF + Logistic Regression ===\n",
      "Accuracy: 0.6038\n",
      "Precision (weighted): 0.6005\n",
      "Recall (weighted):    0.6038\n",
      "F1-score (weighted):  0.5989\n",
      "\n",
      "Detailed Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.60      0.69      0.64       790\n",
      "Extremely Positive       0.64      0.72      0.68      1005\n",
      "          Negative       0.56      0.49      0.52      1516\n",
      "           Neutral       0.64      0.74      0.68      1176\n",
      "          Positive       0.59      0.50      0.54      1687\n",
      "\n",
      "          accuracy                           0.60      6174\n",
      "         macro avg       0.60      0.63      0.61      6174\n",
      "      weighted avg       0.60      0.60      0.60      6174\n",
      "\n",
      "\n",
      "Example of correctly classified tweet:\n",
      "Tweet: What the shops are doing is obeying the law of demand and supply. If we want an ethical distribution of essential consumer items, then we must look to socialism. ThatÂs what we had - with rationing - in WW2, under an ostensibly Conservative PM. #coronavirus #covid19UK #BorisOut\n",
      "Label: Positive\n",
      "\n",
      "Example of wrongly classified tweet:\n",
      "Tweet:  Without the there would not be any problem whatsoever People are getting worried about the supply chain   Prices for key food staples are starting to soar in some parts of the world via\n",
      "True label: Neutral, Predicted: Negative\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "    ('clf', LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'clf__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1, verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid.predict(X_val)\n",
    "evaluate_predictions(y_val, y_pred, val_df['OriginalTweet'], method_name=\"Tuned TF-IDF + Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to stay with the same model, because randomforests was really slow for the amount of data and SVM didn't accomplish to beat the baseline. Instead, I opted for small but meaningful improvements. Although the difference in performance is not huge, I know that in this context, even small improvements can be significant, so I’m satisfied with my results. I added an n-gram search to make the text representation better, since it captures the dependences between words more effectively. I finally chose Grid Search to find better hyperparameters for my model, focusing on the regularization strength C in Logistic Regression. This allowed me to control overfitting and fine-tune the balance between bias and variance.With evaluate predictions I can see that these second model is better at identifying more strong emotions like \"extremely positive\" and \"neutral\" I also liked using class_weighted to help me adress the class imbalance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV-1eX7y4-1_"
   },
   "source": [
    "## Question 6 (15 points)\n",
    "\n",
    "Design, develop and train a **neural network-based classifier** for this task, using scikit-learn, PyTorch or the Transformers library. The scikit-learn approach is demonstrated in Notebook 7_1, the Pytorch approach is demonstrated in Notebook 7_2. The Transformers approach is the most state-of-the-art approach, which involves taking a pre-trained LLM and tuning a sequence classification head for your text classification task. You can find a basic example in the Huggingface documentation: https://huggingface.co/docs/transformers/en/tasks/sequence_classification\n",
    "\n",
    "The scikit-learn option is probably simpler than you think. Pytorch and Transformers classifiers are more advanced and challenging, but due to the current popularity of Transformer models it is relatively easy to find solutions to your problems with Transformer models. If you are up for a challenge, choose Pytorch if you are more interested in foundations of neural networks and machine learning more broadly, or choose Transformers if you are interested in LLMs and textual data.\n",
    "\n",
    "The classifier can have the structure that you prefer and use an embedding model of your choice, just make sure to motivate your choices.\n",
    "\n",
    "*Note: an NN-based classifier with scikit-learn yields 5 points max; one with PyTorch or a pre-tuned Transformers-based model yields 10 points max; one with PyTorch and pre-trained embeddings or a Transformers-based model tuned by yourself yields 15 points max. If you try PyTorch or Transformers but get stuck, you can still get partial points if you have a good explanation of what you tried.*\n",
    "\n",
    "Use your classification report function and the validation set to report on the performance of your baseline. *Pay attention: the validation data only needs to be transformed, and must not be used to fit any transformation. For example, if you have used a TF-IDF vectorizer by fitting it to your train data and then transformed it, use the same fitted vectorizer to transform your validation data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viole\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 16235.97 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 14415.89 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='279' max='279' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [279/279 36:23, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.321523</td>\n",
       "      <td>0.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.131081</td>\n",
       "      <td>0.536000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=279, training_loss=1.2253064664888553, metrics={'train_runtime': 2187.4849, 'train_samples_per_second': 4.114, 'train_steps_per_second': 0.128, 'total_flos': 129628354230000.0, 'train_loss': 1.2253064664888553, 'epoch': 2.970666666666667})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import evaluate\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "# Clean function simpler than in the first exercise because we are using a pretrained model that is already trained on a lot of data and we don't need to do much preprocessing\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)  \n",
    "    text = re.sub(r'#', '', text) \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    return text\n",
    "\n",
    "# Load and clean training data\n",
    "train_df = pd.read_csv(\"data/Corona_NLP_train.csv\", encoding='latin1')\n",
    "train_df[\"clean_tweet\"] = train_df[\"OriginalTweet\"].apply(clean_text)\n",
    "train_df = train_df.sample(n=3000, random_state=42)\n",
    "\n",
    "# Load and clean validation data\n",
    "val_df = pd.read_csv(\"data/Corona_NLP_test.csv\", encoding='latin1')\n",
    "val_df = val_df.sample(n=500, random_state=42)\n",
    "val_df[\"clean_tweet\"] = val_df[\"OriginalTweet\"].apply(clean_text)\n",
    "\n",
    "# Label encoding\n",
    "label_list = train_df['Sentiment'].unique().tolist()\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "train_df[\"label\"] = train_df[\"Sentiment\"].map(label2id)\n",
    "val_df[\"label\"] = val_df[\"Sentiment\"].map(label2id)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_hf = Dataset.from_pandas(train_df[[\"clean_tweet\", \"label\"]])\n",
    "val_hf = Dataset.from_pandas(val_df[[\"clean_tweet\", \"label\"]])\n",
    "\n",
    "# Tokenize using DistilBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"clean_tweet\"], truncation=True)\n",
    "\n",
    "train_tokenized = train_hf.map(tokenize_function, batched=True)\n",
    "val_tokenized = val_hf.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Define accuracy metric\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Data collator to pad batches\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_transformer\",\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=500,    \n",
    "    eval_steps=1000,\n",
    "    gradient_accumulation_steps=4,  # Acumula gradientes\n",
    "    fp16=True  # Usar precisión mixta\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question I used the transformer DistilBERT and Hugging Face's library to load the model and trained it on a subset of the dataset. After cleaning the text and tokenizing it, I trained the model for 3 epochs. The results showed that the model achieved a validation accuracy of around 53%, with a training loss of 1.23 and validation loss of 1.13 after two epochs. Despite being a powerful model, it still has room for improvement, especially when compared to traditional models like Logistic Regression with TF-IDF, model that I used in the other exercises. I believe that this model would work better after more training, but the memory of my computer is really full and it would require a lot of time to do that, this has been charging for an hour. So for using this tranformer I think that larger data would be needed and maybe a little bit more of fine tuning for better feature extraction since TF-IDF captures word-level patterns more directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8K-n8Ak4-2A"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjiTUFSZ4-2A"
   },
   "source": [
    "# Evaluating your classifiers (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9JXwtnF4-2B"
   },
   "source": [
    "## Question 7 (8 points)\n",
    "\n",
    "Evaluate the performance of your models on the **test set**. Make sure to transform your test data as you did for your train data, and as needed for each classifier. *Pay attention: the test data only needs to be transformed, and must not be used to fit any transformation. For example, if you have used a TF-IDF vectorizer by fitting it to your train data and then transformed your train and validation with it, use the same fitted vectorizer to transform your test data.*\n",
    "\n",
    "* Report the accuracy of each classifier, as well as its precision, recall and F1 score. \n",
    "* Plot a [confusion matrix](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) for your best classifier.\n",
    "* Briefly discuss your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)  \n",
    "    text = re.sub(r'#', '', text) \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viole\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'classification_repor' from 'sklearn.metrics' (C:\\Users\\viole\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevaluate\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_repor\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Load test data\u001b[39;00m\n\u001b[32m     14\u001b[39m test_df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/Corona_NLP_test.csv\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mlatin1\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'classification_repor' from 'sklearn.metrics' (C:\\Users\\viole\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import evaluate\n",
    "from sklearn.metrics import classification_repor\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"data/Corona_NLP_test.csv\", encoding='latin1')\n",
    "# Apply same preprocessing to get ProcessedTweet\n",
    "# Apply the same cleaning as for the training data\n",
    "test_df['clean_tweet'] = test_df['OriginalTweet'].apply(clean_text)\n",
    "X_test = test_df['clean_tweet']\n",
    "y_test = test_df['Sentiment']\n",
    "\n",
    "\n",
    "print(\"Evaluating all three models on the test set...\")\n",
    "\n",
    "# 1. EVALUATE BASIC TF-IDF + LOGISTIC REGRESSION\n",
    "# Transform test data with pre-fitted vectorizer\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "# Predict\n",
    "y_pred_model1 = model.predict(X_test_tfidf)\n",
    "\n",
    "# Metrics\n",
    "accuracy1 = accuracy_score(y_test, y_pred_model1)\n",
    "precision1, recall1, f1_1, _ = precision_recall_fscore_support(y_test, y_pred_model1, average='weighted')\n",
    "print(\"\\nModel 1: Basic TF-IDF + Logistic Regression\")\n",
    "print(f\"Accuracy: {accuracy1:.4f}\")\n",
    "print(f\"Precision: {precision1:.4f}\")\n",
    "print(f\"Recall: {recall1:.4f}\")\n",
    "print(f\"F1 Score: {f1_1:.4f}\")\n",
    "\n",
    "# 2. EVALUATE OPTIMIZED TF-IDF + LOGISTIC REGRESSION\n",
    "# Predict using the complete GridSearchCV pipeline\n",
    "y_pred_model2 = grid.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "accuracy2 = accuracy_score(y_test, y_pred_model2)\n",
    "precision2, recall2, f1_2, _ = precision_recall_fscore_support(y_test, y_pred_model2, average='weighted')\n",
    "print(\"\\nModel 2: Optimized TF-IDF + Logistic Regression\")\n",
    "print(f\"Accuracy: {accuracy2:.4f}\")\n",
    "print(f\"Precision: {precision2:.4f}\")\n",
    "print(f\"Recall: {recall2:.4f}\")\n",
    "print(f\"F1 Score: {f1_2:.4f}\")\n",
    "\n",
    "# 3. EVALUATE DISTILBERT MODEL\n",
    "# Clean and map test data with same functions\n",
    "test_df[\"clean_tweet\"] = test_df[\"OriginalTweet\"].apply(clean_text)\n",
    "test_df[\"label\"] = test_df[\"Sentiment\"].map(label2id)\n",
    "\n",
    "# Convert to Hugging Face dataset\n",
    "test_hf = Dataset.from_pandas(test_df[[\"clean_tweet\", \"label\"]])\n",
    "\n",
    "# Tokenize using same tokenizer\n",
    "test_tokenized = test_hf.map(tokenize_function, batched=True)\n",
    "\n",
    "# Make predictions\n",
    "predictions = trainer.predict(test_tokenized)\n",
    "y_pred_model3 = np.argmax(predictions.predictions, axis=-1)\n",
    "y_test_model3 = predictions.label_ids\n",
    "\n",
    "# Metrics\n",
    "accuracy3 = accuracy_score(y_test_model3, y_pred_model3)\n",
    "precision3, recall3, f1_3, _ = precision_recall_fscore_support(y_test_model3, y_pred_model3, average='weighted')\n",
    "print(\"\\nModel 3: DistilBERT\")\n",
    "print(f\"Accuracy: {accuracy3:.4f}\")\n",
    "print(f\"Precision: {precision3:.4f}\")\n",
    "print(f\"Recall: {recall3:.4f}\")\n",
    "print(f\"F1 Score: {f1_3:.4f}\")\n",
    "\n",
    "# Create a summary table of all models for easy comparison\n",
    "model_names = [\"Basic TF-IDF + LR\", \"Optimized TF-IDF + LR\", \"DistilBERT\"]\n",
    "accuracies = [accuracy1, accuracy2, accuracy3]\n",
    "precisions = [precision1, precision2, precision3]\n",
    "recalls = [recall1, recall2, recall3]\n",
    "f1_scores = [f1_1, f1_2, f1_3]\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'F1 Score': f1_scores\n",
    "})\n",
    "\n",
    "print(\"\\nSummary of Model Performance:\")\n",
    "print(summary_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "# Find the best model based on F1 score\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_model = model_names[best_idx]\n",
    "print(f\"\\nBased on F1 Score, the best model is {best_model} with F1 Score of {f1_scores[best_idx]:.4f}\")\n",
    "\n",
    "# PLOTTING CONFUSION MATRIX ONLY FOR THE BEST MODEL (Model 2: Optimized TF-IDF)\n",
    "print(\"\\nPlotting confusion matrix for the best classifier: Optimized TF-IDF + Logistic Regression\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_model2,\n",
    "    display_labels=sorted(test_df['Sentiment'].unique()),\n",
    "    cmap=\"Blues\",\n",
    "    xticks_rotation=45\n",
    ")\n",
    "plt.title(\"Confusion Matrix - Optimized TF-IDF + Logistic Regression\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_best_model.png')\n",
    "plt.show()\n",
    "\n",
    "# Discussion of results\n",
    "print(\"\"\"\n",
    "Discussion of Results:\n",
    "---------------------\n",
    "The optimized TF-IDF + Logistic Regression model achieves the best performance among the three models evaluated.\n",
    "The hyperparameter tuning through GridSearchCV significantly improved the model's ability to classify tweet sentiments\n",
    "compared to the basic TF-IDF model.\n",
    "\n",
    "The confusion matrix shows that the model performs well across most sentiment categories, but there\n",
    "is some confusion between closely related sentiments (e.g., between \"Neutral\" and \"Positive\" or between\n",
    "\"Extremely Negative\" and \"Negative\"). This is expected given the subjective nature of sentiment analysis.\n",
    "\n",
    "While transformer-based models like DistilBERT can capture more complex language patterns, the optimized \n",
    "TF-IDF model provides a good balance between performance and computational efficiency. The fact that we \n",
    "achieved strong results with a relatively simple model indicates that:\n",
    "\n",
    "1. The n-gram features (unigrams and bigrams) effectively capture important sentiment signals in the tweets\n",
    "2. The class weight balancing helps address any class imbalance issues\n",
    "3. The regularization parameter (C) was well-tuned to prevent overfitting\n",
    "\n",
    "For real-world applications related to COVID-19 sentiment analysis, this model offers practical advantages:\n",
    "it's faster to train and deploy, requires fewer computational resources, and provides accurate sentiment\n",
    "predictions that could be valuable for tracking public opinion during health crises.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Preprocess test data using the same TF-IDF vectorizer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m X_test_tfidf = \u001b[43mtfidf\u001b[49m.transform(X_test)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Get predictions for both models\u001b[39;00m\n\u001b[32m      9\u001b[39m baseline_predictions = model.predict(X_test_tfidf)\n",
      "\u001b[31mNameError\u001b[39m: name 'tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocess test data using the same TF-IDF vectorizer\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Get predictions for both models\n",
    "baseline_predictions = model.predict(X_test_tfidf)\n",
    "tuned_predictions = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate both models\n",
    "print(\"Baseline Model Performance:\")\n",
    "evaluate_predictions(y_test, baseline_predictions, test_df['OriginalTweet'], method_name=\"TF-IDF + Logistic Regression\")\n",
    "\n",
    "print(\"\\nTuned Model Performance:\")\n",
    "evaluate_predictions(y_test, tuned_predictions, test_df['OriginalTweet'], method_name=\"Tuned TF-IDF + Logistic Regression\")\n",
    "\n",
    "# Create confusion matrix for the best model (tuned model)\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, tuned_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                             display_labels=test_df['Sentiment'].unique())\n",
    "disp.plot(xticks_rotation=45)\n",
    "plt.title('Confusion Matrix - Tuned TF-IDF + Logistic Regression')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDr66A_j4-2B"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>44958</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>Do you remember the last time you paid $2.99 a...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>44959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>Voting in the age of #coronavirus = hand sanit...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>44960</td>\n",
       "      <td>Geneva, Switzerland</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>@DrTedros \"We cant stop #COVID19 without prot...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>44961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>HI TWITTER! I am a pharmacist. I sell hand san...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>44962</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>Anyone been in a supermarket over the last few...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>44963</td>\n",
       "      <td>Boksburg, South Africa</td>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>Best quality couches at unbelievably low price...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>44964</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>Beware of counterfeits trying to sell fake mas...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>44965</td>\n",
       "      <td>USA, PA</td>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>Panic food buying in Germany due to #coronavir...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>44966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>#Covid_19 Went to the Grocery Store, turns out...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>44967</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>While we were busy watching election returns a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>44968</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>04-03-2020</td>\n",
       "      <td>#AirSewa \\r\\r\\n\\r\\r\\n@flyspicejet is not provi...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>44969</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>05-03-2020</td>\n",
       "      <td>What Precautionary measures have you all taken...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>44970</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>05-03-2020</td>\n",
       "      <td>When youre stockpiling food &amp;amp; other suppl...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>44971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05-03-2020</td>\n",
       "      <td>That's about a week from now. A bit optimistic...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>44972</td>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>05-03-2020</td>\n",
       "      <td>Studies show the #coronavirus like #COVID19 ca...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserName  ScreenName                Location     TweetAt  \\\n",
       "0          1       44953                     NYC  02-03-2020   \n",
       "1          2       44954             Seattle, WA  02-03-2020   \n",
       "2          3       44955                     NaN  02-03-2020   \n",
       "3          4       44956             Chicagoland  02-03-2020   \n",
       "4          5       44957     Melbourne, Victoria  03-03-2020   \n",
       "5          6       44958             Los Angeles  03-03-2020   \n",
       "6          7       44959                     NaN  03-03-2020   \n",
       "7          8       44960     Geneva, Switzerland  03-03-2020   \n",
       "8          9       44961                     NaN  04-03-2020   \n",
       "9         10       44962         Dublin, Ireland  04-03-2020   \n",
       "10        11       44963  Boksburg, South Africa  04-03-2020   \n",
       "11        12       44964               New Delhi  04-03-2020   \n",
       "12        13       44965                 USA, PA  04-03-2020   \n",
       "13        14       44966                     NaN  04-03-2020   \n",
       "14        15       44967          Washington, DC  04-03-2020   \n",
       "15        16       44968              Bengaluru   04-03-2020   \n",
       "16        17       44969                  Mumbai  05-03-2020   \n",
       "17        18       44970        Toronto, Ontario  05-03-2020   \n",
       "18        19       44971                     NaN  05-03-2020   \n",
       "19        20       44972             Tallahassee  05-03-2020   \n",
       "\n",
       "                                        OriginalTweet           Sentiment  \n",
       "0   TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
       "1   When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
       "2   Find out how you can protect yourself and love...  Extremely Positive  \n",
       "3   #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
       "4   #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  \n",
       "5   Do you remember the last time you paid $2.99 a...             Neutral  \n",
       "6   Voting in the age of #coronavirus = hand sanit...            Positive  \n",
       "7   @DrTedros \"We cant stop #COVID19 without prot...             Neutral  \n",
       "8   HI TWITTER! I am a pharmacist. I sell hand san...  Extremely Negative  \n",
       "9   Anyone been in a supermarket over the last few...  Extremely Positive  \n",
       "10  Best quality couches at unbelievably low price...            Positive  \n",
       "11  Beware of counterfeits trying to sell fake mas...  Extremely Negative  \n",
       "12  Panic food buying in Germany due to #coronavir...  Extremely Negative  \n",
       "13  #Covid_19 Went to the Grocery Store, turns out...  Extremely Positive  \n",
       "14  While we were busy watching election returns a...            Positive  \n",
       "15  #AirSewa \\r\\r\\n\\r\\r\\n@flyspicejet is not provi...  Extremely Negative  \n",
       "16  What Precautionary measures have you all taken...  Extremely Positive  \n",
       "17  When youre stockpiling food &amp; other suppl...             Neutral  \n",
       "18  That's about a week from now. A bit optimistic...            Positive  \n",
       "19  Studies show the #coronavirus like #COVID19 ca...  Extremely Positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"data/Corona_NLP_test.csv\")\n",
    "df_test.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF + Logistic Regression Performance:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.63      0.68      0.65       619\n",
      "          Positive       0.63      0.47      0.54       592\n",
      "Extremely Positive       0.50      0.63      0.56       947\n",
      "          Negative       0.52      0.53      0.53      1041\n",
      "           Neutral       0.70      0.52      0.60       599\n",
      "\n",
      "          accuracy                           0.57      3798\n",
      "         macro avg       0.60      0.57      0.57      3798\n",
      "      weighted avg       0.58      0.57      0.57      3798\n",
      "\n",
      "\n",
      "Tuned TF-IDF + Logistic Regression Performance:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Reporte de clasificación para el modelo afinado TF-IDF + Regresión Logística\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTuned TF-IDF + Logistic Regression Performance:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_pred_tuned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSentiment\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Mostrar la matriz de confusión para el mejor modelo afinado\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mConfusion Matrix for Tuned TF-IDF + Logistic Regression:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:2674\u001b[39m, in \u001b[36mclassification_report\u001b[39m\u001b[34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[39m\n\u001b[32m   2671\u001b[39m y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     labels = \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2675\u001b[39m     labels_given = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\multiclass.py:117\u001b[39m, in \u001b[36munique_labels\u001b[39m\u001b[34m(*ys)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(label, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ys_labels)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMix of label input types (string and number)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(\u001b[38;5;28msorted\u001b[39m(ys_labels))\n",
      "\u001b[31mValueError\u001b[39m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Asegúrate de que las columnas 'clean_tweet' contienen texto antes de la transformación\n",
    "df_train['clean_tweet'] = df_train['OriginalTweet'].apply(clean_text)  # Asegúrate de que la columna esté procesada\n",
    "\n",
    "# Prepara los datos para el entrenamiento\n",
    "X_train_tfidf = tfidf.fit_transform(df_train['clean_tweet'])  # Ajuste de TF-IDF en datos de entrenamiento\n",
    "y_train = df_train['Sentiment'].map(label2id)\n",
    "\n",
    "# Entrenar el modelo de regresión logística\n",
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "model_lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Preprocesar los tweets de prueba y aplicar el vectorizador TF-IDF ajustado\n",
    "X_test_tfidf = tfidf.transform(df_test['clean_tweet'])  # Usa 'clean_tweet' para asegurar que es texto\n",
    "\n",
    "# Hacer las predicciones\n",
    "y_test_pred_lr = model_lr.predict(X_test_tfidf)\n",
    "\n",
    "# Reporte de clasificación para el modelo TF-IDF + Regresión Logística\n",
    "print(\"\\nTF-IDF + Logistic Regression Performance:\")\n",
    "print(classification_report(y_test, y_test_pred_lr, target_names=df_test['Sentiment'].unique()))\n",
    "\n",
    "# Evaluar el modelo con hiperparámetros afinados (si ya se ha ajustado el modelo con GridSearchCV)\n",
    "X_test_tfidf_tuned = tfidf.transform(df_test['clean_tweet'])  # Asegúrate de usar la columna correcta\n",
    "\n",
    "# Predicciones con el mejor modelo ajustado\n",
    "y_test_pred_tuned = grid.predict(df_test['clean_tweet'])\n",
    "\n",
    "# Reporte de clasificación para el modelo afinado TF-IDF + Regresión Logística\n",
    "print(\"\\nTuned TF-IDF + Logistic Regression Performance:\")\n",
    "print(classification_report(y_test, y_test_pred_tuned, target_names=df_test['Sentiment'].unique()))\n",
    "\n",
    "# Mostrar la matriz de confusión para el mejor modelo afinado\n",
    "print(\"\\nConfusion Matrix for Tuned TF-IDF + Logistic Regression:\")\n",
    "cm = confusion_matrix(y_test, y_test_pred_tuned)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=df_test['Sentiment'].unique())\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp.plot()\n",
    "plt.title('Confusion Matrix - Tuned TF-IDF + Logistic Regression')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFviO9dr4-2B"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRm9J4-o4-2C"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKxvAsxg4-2C",
    "tags": []
   },
   "source": [
    "## Question 8 (7 points)\n",
    "\n",
    "When you perform a classification or labeling task, you may want to perform an error analysis to look for avenues for improvement. You can do this both quantitatively and qualitatively.\n",
    "\n",
    "For your best classifier:\n",
    "* Collect misclassified samples, e.g. by modifying your evaluation code from Question 7.\n",
    "\n",
    "Perform a brief quantitative error analysis of your best classifier:\n",
    "* Choose some properties that you think are relevant to classification quality, such as the length of the tweet or use of emoji. Come up with three interesting properties.\n",
    "* Compute and compare these three properties for the misclassified samples to the average distribution over all samples.\n",
    "* Describe your conclusions.\n",
    "\n",
    "Perform a brief qualitative error analysis of your best classifier:\n",
    "* Look at the misclassified samples, and make observations about their properties. Identify some properties that you think are relevant to classification quality but that you can't easily quantify, such as usage of sarcasm or irony, negation issues (not bad != bad), spelling or grammar issues, interpretation of emojis, context dependence of the tweet, or other observations.\n",
    "* Describe your conclusions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect misclassified samples\n",
    "misclassified_samples = df_test[transformer_preds != y_test]\n",
    "misclassified_samples['Predicted'] = transformer_preds[transformer_preds != y_test]\n",
    "misclassified_samples['True'] = y_test[transformer_preds != y_test]\n",
    "# Property 1: Length of tweet\n",
    "df_test['tweet_length'] = df_test['clean_tweet'].apply(len)\n",
    "misclassified_samples['tweet_length'] = misclassified_samples['clean_tweet'].apply(len)\n",
    "\n",
    "# Property 2: Use of emoji (simple example, you can expand with more complex regex)\n",
    "emoji_pattern = re.compile(\"[\"u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map\n",
    "                            u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                            u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                            u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                            u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                            u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                            u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                            u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                            \"]+\", flags=re.UNICODE)\n",
    "\n",
    "df_test['contains_emoji'] = df_test['OriginalTweet'].apply(lambda x: bool(emoji_pattern.search(x)))\n",
    "misclassified_samples['contains_emoji'] = misclassified_samples['OriginalTweet'].apply(lambda x: bool(emoji_pattern.search(x)))\n",
    "\n",
    "# Property 3: Use of hashtags\n",
    "df_test['contains_hashtag'] = df_test['OriginalTweet'].apply(lambda x: '#' in x)\n",
    "misclassified_samples['contains_hashtag'] = misclassified_samples['OriginalTweet'].apply(lambda x: '#' in x)\n",
    "# Compare averages\n",
    "average_properties = df_test[['tweet_length', 'contains_emoji', 'contains_hashtag']].mean()\n",
    "misclassified_properties = misclassified_samples[['tweet_length', 'contains_emoji', 'contains_hashtag']].mean()\n",
    "\n",
    "print(\"Average properties of all samples:\")\n",
    "print(average_properties)\n",
    "print(\"\\nAverage properties of misclassified samples:\")\n",
    "print(misclassified_properties)\n",
    "\n",
    "# Calculate differences\n",
    "property_diff = misclassified_properties - average_properties\n",
    "print(\"\\nDifference between misclassified and all samples:\")\n",
    "print(property_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONz1PmOM4-2E"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2z2g9eF4-2E"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_a3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
